{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beadadfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "def getData(mode):\n",
    "    if mode == 'train':\n",
    "        df = pd.read_csv('train.csv')\n",
    "        path = df['Path'].tolist()\n",
    "        label = df['label'].tolist()\n",
    "        return path, label\n",
    "    \n",
    "    elif mode == 'valid':\n",
    "        df = pd.read_csv('valid.csv')\n",
    "        path = df['Path'].tolist()\n",
    "        label = df['label'].tolist()\n",
    "        return path, label\n",
    "    \n",
    "    else:\n",
    "        df = pd.read_csv('resnet_18_test.csv')\n",
    "        path = df['Path'].tolist()\n",
    "        return path\n",
    "\n",
    "class RetinopathyLoader(data.Dataset):\n",
    "    def __init__(self, root, mode):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root (string): Root path of the dataset.\n",
    "            mode : Indicate procedure status(training or testing)\n",
    "\n",
    "            self.img_name (string list): String list that store all image names.\n",
    "            self.label (int or float list): Numerical list that store all ground truth label values.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        self.mode = mode\n",
    "        \n",
    "        if mode == 'train' or mode == 'valid':\n",
    "            self.img_name, self.label = getData(mode)\n",
    "        else:  # mode == 'test'\n",
    "            self.img_name = getData(mode)\n",
    "            self.label = None  # No labels for test data\n",
    "            \n",
    "        # print(\"> Found %d images...\" % (len(self.img_name)))\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"'return the size of dataset\"\"\"\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \"\"\"\n",
    "           step1. Get the image path from 'self.img_name' and load it.\n",
    "                  hint : path = root + self.img_name[index] + '.jpeg'\n",
    "\n",
    "           step2. Get the ground truth label from self.label\n",
    "\n",
    "           step3. Transform the .jpeg rgb images during the training phase, such as resizing, random flipping, \n",
    "                  rotation, cropping, normalization etc. But at the beginning, I suggest you follow the hints. \n",
    "\n",
    "                  In the testing phase, if you have a normalization process during the training phase, you only need \n",
    "                  to normalize the data. \n",
    "\n",
    "                  hints : Convert the pixel value to [0, 1]\n",
    "                          Transpose the image shape from [H, W, C] to [C, H, W]\n",
    "\n",
    "            step4. Return processed image and label\n",
    "        \"\"\"\n",
    "\n",
    "        img_path = os.path.join(self.root, self.img_name[index]) # + '.jpeg'\n",
    "        img = Image.open(img_path)\n",
    "        \n",
    "        if self.mode == 'train':\n",
    "            transform=transforms.Compose([\n",
    "                transforms.CenterCrop(400), # crops the center region of the image with a square size of height\n",
    "                # transforms.Resize(400), # (h, w) 512x512 pixels\n",
    "                transforms.RandomHorizontalFlip(), #  randomly flips the image horizontally with a 50% chance\n",
    "                transforms.RandomRotation(degrees=15), # randomly rotates the image by a maximum of 15 degree\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                # Add an additional transformation to rescale pixel values to [0, 1]\n",
    "                # transforms.Lambda(lambda x: (x + 1.0) / 2.0)\n",
    "            ])\n",
    "        elif self.mode == 'valid':\n",
    "            transform=transforms.Compose([\n",
    "                transforms.CenterCrop(400),\n",
    "                # transforms.Resize(400),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "                # Add an additional transformation to rescale pixel values to [0, 1]\n",
    "                # transforms.Lambda(lambda x: (x + 1.0) / 2.0)\n",
    "            ])\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.CenterCrop(400),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        \n",
    "        img = transform(img) \n",
    "        \n",
    "        # print(img[0].shape)\n",
    "        \n",
    "        if self.label is not None:\n",
    "            label = self.label[index]\n",
    "            return img, label\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1a90aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1067"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(514)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = RetinopathyLoader(root = \".\", mode=\"train\")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "valid_dataset = RetinopathyLoader(root = \".\", mode=\"valid\")\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = RetinopathyLoader(root = \".\", mode=\"test\")\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# train_cnt = len(train_loader.dataset)\n",
    "# print(train_cnt) # 7995\n",
    "\n",
    "# valid_cnt = len(valid_loader.dataset)\n",
    "# valid_cnt # 1599\n",
    "\n",
    "test_cnt = len(test_loader.dataset)\n",
    "test_cnt # 1067"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b36a195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_device():\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "device = get_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a8a6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, prev_channel, in_channel, out_channel, stride=(1, 1), downsample=False):\n",
    "        super().__init__()\n",
    "                \n",
    "        # First bottleneck block needs to be downsampled\n",
    "        if downsample: \n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(prev_channel, out_channel, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "                nn.BatchNorm2d(out_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.Conv2d(out_channel, out_channel, kernel_size=(3, 3), stride=stride, padding=(1, 1), bias=False),\n",
    "                nn.BatchNorm2d(out_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.Conv2d(out_channel, in_channel, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "                nn.BatchNorm2d(in_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            )\n",
    "            self.down_sample = nn.Sequential(\n",
    "                nn.Conv2d(prev_channel, in_channel, kernel_size=(1,1), stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(in_channel)\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                nn.Conv2d(in_channel, out_channel, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "                nn.BatchNorm2d(out_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.Conv2d(out_channel, out_channel, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
    "                nn.BatchNorm2d(out_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                nn.Conv2d(out_channel, in_channel, kernel_size=(1, 1), stride=(1, 1), bias=False),\n",
    "                nn.BatchNorm2d(in_channel, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "            )\n",
    "            self.down_sample = nn.Identity()\n",
    "            \n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        residual = self.down_sample(x)\n",
    "        out = self.ReLU(out + residual)\n",
    "        return out\n",
    "\n",
    "def add_bottleneck_blocks(prev_channel, in_channel, out_channel, stride): #, num_blocks):\n",
    "    bottleneck_blocks = []\n",
    "    bottleneck_blocks.append(BottleneckBlock(prev_channel, in_channel, out_channel, stride, True))\n",
    "    bottleneck_blocks.append(BottleneckBlock(prev_channel, in_channel, out_channel))\n",
    "    bottleneck_blocks.append(BottleneckBlock(prev_channel, in_channel, out_channel))\n",
    "    return bottleneck_blocks\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n",
    "            nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True,),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=1, ceil_mode=False),\n",
    "        )\n",
    "        \n",
    "        # Each layer has 3 bottleneck blocks\n",
    "        self.layer1 = nn.Sequential(*add_bottleneck_blocks(64, 64, 256, (1, 1))) \n",
    "        self.layer2 = nn.Sequential(*add_bottleneck_blocks(256, 128, 512, (2, 2))) \n",
    "        self.layer3 = nn.Sequential(*add_bottleneck_blocks(512, 256, 1024, (2, 2)))\n",
    "        self.layer4 = nn.Sequential(*add_bottleneck_blocks(1024, 512, 2048, (2, 2)))\n",
    "\n",
    "        # self.avg_pool = nn.AvgPool2d(kernal_size=7, stride=1, padding=0)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1, 1)) # (output_H, output_W)\n",
    "        self.fc = nn.Linear(2048, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.conv1(x)\n",
    "        output = self.layer1(output)\n",
    "        output = self.layer2(output)\n",
    "        output = self.layer3(output)\n",
    "        output = self.layer4(output)              # print(output.shape) (num, 512, n, n)\n",
    "        output = self.avg_pool(output)            # print(output.shape) (num, 512, 1, 1)\n",
    "        # out = nn.flatten(out)\n",
    "        output = output.view(output.shape[0], -1) # print(output.shape) (num, 512)\n",
    "        output = self.fc(output)                  # print(output.shape) (num, 2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d31504dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "valid_acc = []\n",
    "predicted_list = []\n",
    "predicted_label = []\n",
    "test_predicted_label = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2b8404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_loop(num_epoch, train_loader, test_loader, model, loss_fn, optimizer):\n",
    "    best_acc = 0\n",
    "    for e in range(num_epoch):\n",
    "        global predicted_list\n",
    "        predicted_list = []\n",
    "        train_acc = train(train_loader, model, loss_fn, optimizer)\n",
    "        valid_acc = valid(valid_loader, model, loss_fn)\n",
    "        if (e % (num_epoch//10)) == 0:\n",
    "            print(f'Epoch: {e:5}, train_acc:{train_acc:.2f}%')\n",
    "            print(f'Epoch: {e:5}, valid_acc:{valid_acc:.2f}%')\n",
    "            print(f'Current best acc: {best_acc:.2f}%')\n",
    "        if valid_acc > best_acc:\n",
    "            global predicted_label\n",
    "            predicted_label = predicted_list\n",
    "            best_acc = valid_acc\n",
    "            torch.save(model.state_dict(), \"ResNet50_\"+str(optimizer.__class__.__name__)+\".pth\")\n",
    "            '''\n",
    "            print(\"Model state dict:\")\n",
    "            for param_tensor in model.state_dict():\n",
    "                print(param_tensor, \"\\t\", model.state_dict()[param_tensor])\n",
    "            print(\"Model save\")\n",
    "            '''\n",
    "        if (e+1) == num_epoch:\n",
    "            print(f'best acc: {best_acc:.2f}%')\n",
    "            \n",
    "def train(train_loader, model, loss_fn, optimizer):\n",
    "    model.train() \n",
    "    match_train_cnt = 0\n",
    "    total_cnt = len(train_loader.dataset)\n",
    "    \n",
    "    for i, (train_data, train_label) in enumerate(train_loader):\n",
    "        train_data = train_data.to(device)\n",
    "        train_label = train_label.to(device).to(torch.long)\n",
    "\n",
    "        output = model(train_data)\n",
    "        loss = loss_fn(output, train_label)\n",
    "\n",
    "        pred = torch.max(output, dim=1) \n",
    "        match_train_cnt += (pred[1] == train_label).sum().item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    acc = match_train_cnt / total_cnt * 100\n",
    "    train_acc.append(acc)\n",
    "    return acc\n",
    "        \n",
    "def valid(valid_loader, model, loss_fn):\n",
    "    # Step 5: Testing loop\n",
    "    model.eval()\n",
    "    match_valid_cnt = 0\n",
    "    total_cnt = len(valid_loader.dataset)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (valid_data, valid_label) in enumerate(valid_loader):   \n",
    "            valid_data = valid_data.to(device)\n",
    "            valid_label = valid_label.to(device).to(torch.long)\n",
    "            output = model(valid_data)\n",
    "            pred = torch.max(output, dim=1)\n",
    "            match_valid_cnt += (pred[1] == valid_label).sum().item()\n",
    "            \n",
    "            # Convert the ground truth labels and predicted labels to NumPy arrays and \n",
    "            # Retrieve the indices corresponding to their maximum values\n",
    "            # true_label.extend(valid_label.cpu().data.numpy())\n",
    "            predicted_list.append(pred[1].cpu().data.numpy())\n",
    "\n",
    "    acc = match_valid_cnt / total_cnt * 100\n",
    "    valid_acc.append(acc)\n",
    "    return acc\n",
    "\n",
    "def test(test_loader, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, test_data in enumerate(test_loader):\n",
    "            test_data = test_data.to(device)\n",
    "            output = model(test_data)\n",
    "            pred = torch.max(output, dim=1)\n",
    "            test_predicted_label.append(pred[1].cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "03dddcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_result():\n",
    "    best_train_acc = 0\n",
    "    best_valid_acc = 0\n",
    "    for i in range(num_epoch):\n",
    "        best_train_acc = max(best_train_acc, train_acc[i])\n",
    "        best_valid_acc = max(best_valid_acc, valid_acc[i])\n",
    "    \n",
    "    plt.title('Accuracy Curve(ResNet50)')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy(%)')\n",
    "\n",
    "    plt.plot(train_acc, label = 'ResNet50_train', color = 'b')\n",
    "    plt.plot(valid_acc, label = 'ResNet50_valid', color = 'r')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f'Best train acc: {best_train_acc:.2f}%, Best valid acc: {best_valid_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c705098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_label, predicted_label, classes, normalize = False, title = None, cmap = plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true_label, predicted_label)\n",
    "    \n",
    "    # Calculate class-wise accuracy if normalization is enabled\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57a00a18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 11.99 GiB total capacity; 25.20 GiB already allocated; 0 bytes free; 25.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-4\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m epoch_loop(num_epoch, train_loader, valid_loader, model, loss_fn, optimizer)\n",
      "Cell \u001b[1;32mIn[27], line 6\u001b[0m, in \u001b[0;36mepoch_loop\u001b[1;34m(num_epoch, train_loader, test_loader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m predicted_list\n\u001b[0;32m      5\u001b[0m predicted_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 6\u001b[0m train_acc \u001b[38;5;241m=\u001b[39m train(train_loader, model, loss_fn, optimizer)\n\u001b[0;32m      7\u001b[0m valid_acc \u001b[38;5;241m=\u001b[39m valid(valid_loader, model, loss_fn)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (e \u001b[38;5;241m%\u001b[39m (num_epoch\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn[27], line 35\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     32\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     33\u001b[0m train_label \u001b[38;5;241m=\u001b[39m train_label\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mlong)\n\u001b[1;32m---> 35\u001b[0m output \u001b[38;5;241m=\u001b[39m model(train_data)\n\u001b[0;32m     36\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(output, train_label)\n\u001b[0;32m     38\u001b[0m pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[31], line 68\u001b[0m, in \u001b[0;36mResNet50.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     67\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[1;32m---> 68\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(output)\n\u001b[0;32m     69\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(output)\n\u001b[0;32m     70\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(output)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[31], line 35\u001b[0m, in \u001b[0;36mBottleneckBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x)\n\u001b[0;32m     34\u001b[0m residual \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_sample(x)\n\u001b[1;32m---> 35\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mReLU(out \u001b[38;5;241m+\u001b[39m residual)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 158.00 MiB (GPU 0; 11.99 GiB total capacity; 25.20 GiB already allocated; 0 bytes free; 25.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num_epoch = 101\n",
    "model = ResNet50().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4, momentum=0.9)\n",
    "epoch_loop(num_epoch, train_loader, valid_loader, model, loss_fn, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf7b601",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result()\n",
    "\n",
    "_, true_label = getData('valid')\n",
    "predicted_label = np.concatenate(predicted_label).tolist()\n",
    "plot_confusion_matrix(true_label, predicted_label, ['0', '1'], title = 'Confusion matrix of ResNet50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and show best acc on valid dataset\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "model = ResNet50().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4, momentum=0.9)\n",
    "filename = \"ResNet50_\"+str(optimizer.__class__.__name__)+\".pth\"\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.eval()\n",
    "best_acc = valid(valid_loader, model, loss_fn)\n",
    "print(f'Best valid acc: {best_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f5215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and run on test data then write to csv\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "model = ResNet50().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, weight_decay=5e-4, momentum=0.9)\n",
    "filename = \"ResNet50_\"+str(optimizer.__class__.__name__)+\".pth\"\n",
    "model.load_state_dict(torch.load(filename))\n",
    "model.eval()\n",
    "test(test_loader, model)\n",
    "test_predicted_label = np.concatenate(test_predicted_label).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3764109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def write_to_csv(image_paths, labels, output_file):\n",
    "    df = pd.DataFrame({'ID': image_paths, 'label': labels})\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "image_paths = getData('test')\n",
    "\n",
    "labels = test_predicted_label\n",
    "\n",
    "output_file = \"resnet_50_test_SGD.csv\"\n",
    "\n",
    "write_to_csv(image_paths, labels, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
